{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14224116,"sourceType":"datasetVersion","datasetId":9073905},{"sourceId":14224155,"sourceType":"datasetVersion","datasetId":9073933},{"sourceId":14224494,"sourceType":"datasetVersion","datasetId":9074191}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# =====================================================\n# 1. LOAD DATA\n# =====================================================\n\nsales_df = pd.read_csv(\"/kaggle/input/cleaned-1/prod_store_sales_header (1).csv\")\ncustomers_df = pd.read_csv(\"/kaggle/input/remaining-data/customer_details (1).csv\")\nloyalty_rules_df = pd.read_csv(\"/kaggle/input/remaining-data/loyalty_rules (1).csv\")\n\n# Ensure numeric\nsales_df[\"total_amount\"] = sales_df[\"total_amount\"].astype(float)\n\n# =====================================================\n# 2. SCHEMA STANDARDIZATION (PROFESSIONAL STEP)\n# =====================================================\n# Preserve original column, add semantic alias\n\nif \"points_per_unit_spend\" not in loyalty_rules_df.columns:\n    raise ValueError(\"Expected column 'points_per_unit_spend' missing in loyalty_rules\")\n\nloyalty_rules_df[\"points_per_rupee\"] = loyalty_rules_df[\"points_per_unit_spend\"]\n\n# Optional bonus columns (safe defaults)\nif \"bonus_threshold\" not in loyalty_rules_df.columns:\n    loyalty_rules_df[\"bonus_threshold\"] = None\n\nif \"bonus_points\" not in loyalty_rules_df.columns:\n    loyalty_rules_df[\"bonus_points\"] = 0\n\n# =====================================================\n# 3. READ LOYALTY RULES\n# =====================================================\n\nrule = loyalty_rules_df.iloc[0]\n\nPOINTS_PER_RUPEE = rule[\"points_per_rupee\"]\nBONUS_THRESHOLD = rule[\"bonus_threshold\"]\nBONUS_POINTS = rule[\"bonus_points\"]\n\n# =====================================================\n# 4. CALCULATE LOYALTY POINTS PER TRANSACTION\n# =====================================================\n\ndef calculate_points(amount):\n    points = amount * POINTS_PER_RUPEE\n\n    if pd.notna(BONUS_THRESHOLD) and amount >= BONUS_THRESHOLD:\n        points += BONUS_POINTS\n\n    return int(points)\n\nsales_df[\"earned_points\"] = sales_df[\"total_amount\"].apply(calculate_points)\n\n# =====================================================\n# 5. TRANSACTION-LEVEL OUTPUT\n# =====================================================\n\ntxn_points_df = sales_df[\n    [\n        \"transaction_id\",\n        \"customer_id\",\n        \"transaction_date\",\n        \"total_amount\",\n        \"earned_points\"\n    ]\n]\n\n# =====================================================\n# 6. AGGREGATE POINTS PER CUSTOMER\n# =====================================================\n\ncustomer_points = (\n    txn_points_df\n    .groupby(\"customer_id\")[\"earned_points\"]\n    .sum()\n    .reset_index()\n    .rename(columns={\"earned_points\": \"new_points\"})\n)\n\n# =====================================================\n# 7. UPDATE CUSTOMER MASTER\n# =====================================================\n\nif \"loyalty_points\" not in customers_df.columns:\n    customers_df[\"loyalty_points\"] = 0\n\ncustomers_df = customers_df.merge(\n    customer_points,\n    on=\"customer_id\",\n    how=\"left\"\n)\n\ncustomers_df[\"new_points\"] = customers_df[\"new_points\"].fillna(0)\ncustomers_df[\"loyalty_points\"] += customers_df[\"new_points\"]\n\ncustomers_df.drop(columns=[\"new_points\"], inplace=True)\n\n# =====================================================\n# 8. SAVE OUTPUTS\n# =====================================================\n\ntxn_points_df.to_csv(\"transaction_loyalty_points.csv\", index=False)\ncustomers_df.to_csv(\"customer_details_updated.csv\", index=False)\n\nprint(\"✅ Loyalty Point Calculation Engine executed successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T12:48:03.801344Z","iopub.execute_input":"2025-12-19T12:48:03.801724Z","iopub.status.idle":"2025-12-19T12:48:03.909722Z","shell.execute_reply.started":"2025-12-19T12:48:03.801688Z","shell.execute_reply":"2025-12-19T12:48:03.908695Z"}},"outputs":[{"name":"stdout","text":"✅ Loyalty Point Calculation Engine executed successfully.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}